{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W23LcRScf6-S"
      },
      "source": [
        "# GPT Chat Completion Lab\n",
        "\n",
        "Welcome! In this mini-lab we will explore how to build a playful yet practical chat assistant using the GPT 5 models. The goal is to make the workflow clear enough for beginners while giving you a template you can adapt for your usecases.\n",
        "\n",
        "Objectives:\n",
        "- Build a basic GPT-powered chat assistant  \n",
        "- Adjust assistant behavior using system prompts  \n",
        "- Build a simple Gradio UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i55vtKX9f6-U"
      },
      "source": [
        "## Game Plan\n",
        "- **Context:** We are using Google Colab, so everything happens in the cloud.\n",
        "- **Model:** `gpt-5-nano` keeps responses smart while staying cost-efficient.\n",
        "- **Secret management:** We read the API key from the Colab secret named `OpenAI_API_Key`.\n",
        "- **Flow:** install the SDK â†’ load the key securely â†’ define a helper function â†’ experiment with prompts.\n",
        "- **Stretch idea:** tweak the conversation style and system prompt with your own ideas.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "MODEL=\"gpt-5-nano\""
      ],
      "metadata": {
        "id": "6V2GzCq47uqQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90urDtAwf6-V"
      },
      "source": [
        "## Load Secrets (No Hard-Coding!)\n",
        "Colab lets us keep keys in the `userdata` vault. Make sure your workspace already stores `OpenAI_API_Key`; otherwise run `userdata.set_secret` once (never share the value).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bTQdB0Yvf6-V"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = userdata.get('OpenAI_API_Key')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou_qMNtYf6-V"
      },
      "source": [
        "## Wrap the GPT Client\n",
        "We use the official `openai` package. The helper below:\n",
        "1. Initializes a single `OpenAI` client.\n",
        "2. Accepts a system message and a list of user turns.\n",
        "3. Returns the model reply plus token usage so we can discuss cost control.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=MODEL,\n",
        "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
        ")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "id": "wXdFkxJ3iugG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a86d12ea-5e92-4fc4-d428-4951368eff4d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(id='resp_038efadbbb25fe8600691cd1dcee20819db8f5a0913d6c04f0', created_at=1763496412.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_038efadbbb25fe8600691cd1dd2a30819d8382e67521b033a1', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_038efadbbb25fe8600691cd1dfd360819d9ad1e3510fd05d5d', content=[ResponseOutputText(annotations=[], text='Under a sleepy moon, a gentle unicorn trotted through a starlit meadow and curled up in the whispering grass, finally drifting off to dreamland.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=17, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=486, output_tokens_details=OutputTokensDetails(reasoning_tokens=448), total_tokens=503), user=None, billing={'payer': 'developer'}, prompt_cache_retention=None, store=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage.output_tokens"
      ],
      "metadata": {
        "id": "xh9yN9STz4nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52f9a3b-c9a6-4179-ac41-fb76084c5ec3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "486"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's extract the reply part only:"
      ],
      "metadata": {
        "id": "e6a9hT4ckUH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "EDGGZasgjiQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b67ef0-f011-4703-850c-5878b01ad50e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Under a sleepy moon, a gentle unicorn trotted through a starlit meadow and curled up in the whispering grass, finally drifting off to dreamland.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Instructions\n",
        "Formerly known as system/developer prompt. The instructions parameter sets high-level guidance for how the model should behaveâ€”its tone, goals, and styleâ€”while message roles give more specific, task-level directions.\n"
      ],
      "metadata": {
        "id": "dnc_cKFBpPy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/soltaniehha/Business-Analytics-Toolbox/master/docs/images/Prof-Owl-1.png\"\n",
        "     width=\"300\">\n"
      ],
      "metadata": {
        "id": "3cgtRdAerkMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = \"You are Professor Owl, a wise but approachable teacher. Give clear, simple explanations and gently guide students without sounding formal.\"\n",
        "input = \"why do data analysts prefer Python or SQL instead of Excel for big datasets?\"\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=MODEL,\n",
        "    instructions=instructions,   # Formerly known as system prompt\n",
        "    input=input,                 # User prompt\n",
        "    text={ \"verbosity\": \"low\" }  # Low: short, concise outputs â€” High: detailed explanations or big refactors\n",
        ")\n",
        "\n",
        "Markdown(response.output_text)"
      ],
      "metadata": {
        "id": "jQWnIpPglvV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "f25c9623-136a-4337-9c8c-c5b991bcd72a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Great question. For big datasets, Python or SQL beat Excel for several practical reasons:\n\n- Scale and speed\n  - Databases (SQL) are built for huge data and fast queries with indexing, partitioning, and optimized storage.\n  - Python (with pandas, or tools like Dask/PySpark) can handle larger-than-Excel workloads and can be distributed or chunked.\n\n- Reproducibility and automation\n  - Code-based workflows can be saved, version-controlled, and rerun with new data.\n  - Excel files are manual and easy to break with small changes; formulas and steps arenâ€™t as transparent or auditable.\n\n- Data integrity and governance\n  - SQL enforces data types and constraints; centralized, single source of truth is easier to maintain.\n  - Excel copies data across files, increasing drift and mistakes.\n\n- Complex data operations\n  - SQL shines at joins, aggregations, and filtering across many tables.\n  - Python offers advanced analytics, machine learning, and complex transformations with clear code.\n\n- Collaboration\n  - Databases and code-based workflows are better for teams (shared access, versioning, reviews).\n  - Excel files can collide when multiple people edit them.\n\n- Ecosystem and integration\n  - Python has rich libraries (pandas, numpy, scikit-learn) and dashboards/tools that integrate with data stores.\n  - SQL integrates with data warehouses and BI tools natively.\n\nWhen Excel is fine: for small, quick, ad-hoc analyses, or when you need a simple stakeholder-friendly sheet.\n\nIf youâ€™re starting: learn SQL basics, then Python for more advanced analysis and automation."
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat History"
      ],
      "metadata": {
        "id": "Y-aeunFKv32y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep history\n",
        "history = [{\"role\": \"developer\", \"content\": instructions}]\n",
        "\n",
        "def chat(message):\n",
        "    history.append({\"role\": \"user\", \"content\": message})  # Add the new user message to history\n",
        "\n",
        "    # Send entire history to the model\n",
        "    response = client.responses.create(\n",
        "        model=MODEL,\n",
        "        input=history,\n",
        "        text={ \"verbosity\": \"low\" }\n",
        "    )\n",
        "\n",
        "    # Add model response to history\n",
        "    history.append({\"role\": \"assistant\", \"content\": response.output_text})\n",
        "\n",
        "    return response.output_text"
      ],
      "metadata": {
        "id": "VjSQ771duhdJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(chat(input))"
      ],
      "metadata": {
        "id": "JloK9KRtujRr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "90378bae-75c1-4b1f-eff3-f530bf49b0a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Short answer: Excel isnâ€™t built to handle big data the way Python or SQL are. Hereâ€™s why:\n\n- Scale and speed\n  - Excel has row/memory limits and can slow to a crawl with large files.\n  - SQL databases and Python (with libraries like pandas, Dask) can process terabytes of data, using indexing, parallelism, and optimized engines.\n\n- Data manipulation power\n  - SQL shines at joins, aggregates, window functions, and set-based operations on large tables.\n  - Python lets you do complex cleaning, modeling, and custom logic, and you can chain steps into repeatable scripts.\n\n- Reproducibility and automation\n  - SQL and Python scripts can be version-controlled, tested, and run in automated pipelines.\n  - Excel files are hard to track changes in, prone to manual errors, and harder to reproduce exactly.\n\n- Collaboration and governance\n  - Databases provide centralized data, access controls, and audit trails.\n  - Excel files can get out of sync when shared.\n\n- Ecosystem and integration\n  - SQL connects directly to data warehouses and BI tools; Python can orchestrate workflows, pull data from APIs, and build models.\n  - Excel is great for quick ad-hoc checks, but not as a backbone for big data workflows.\n\nWhen Excel still makes sense: for small datasets, quick ad-hoc analysis, or a simple scratchpad.\n\nTip: For big datasets, start with SQL to fetch and summarize data, then use Python for deeper analysis or modeling."
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat(\"Please highlight the most important point\")"
      ],
      "metadata": {
        "id": "4dPpqHsRwGfo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0a87a3f5-229f-4726-be39-f1e26220bfd7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Key point: Excel isnâ€™t built for big data. For large datasets, use SQL (for scalable querying/aggregation) and Python (for deeper analysis), because they handle volume, speed, and reproducibility much better.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "SLIJdBtjuk-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6bd5107-ab2b-45f9-cd37-688f5614f988"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'developer',\n",
              "  'content': 'You are Professor Owl, a wise but approachable teacher. Give clear, simple explanations and gently guide students without sounding formal.'},\n",
              " {'role': 'user',\n",
              "  'content': 'why do data analysts prefer Python or SQL instead of Excel for big datasets?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Short answer: Excel isnâ€™t built to handle big data the way Python or SQL are. Hereâ€™s why:\\n\\n- Scale and speed\\n  - Excel has row/memory limits and can slow to a crawl with large files.\\n  - SQL databases and Python (with libraries like pandas, Dask) can process terabytes of data, using indexing, parallelism, and optimized engines.\\n\\n- Data manipulation power\\n  - SQL shines at joins, aggregates, window functions, and set-based operations on large tables.\\n  - Python lets you do complex cleaning, modeling, and custom logic, and you can chain steps into repeatable scripts.\\n\\n- Reproducibility and automation\\n  - SQL and Python scripts can be version-controlled, tested, and run in automated pipelines.\\n  - Excel files are hard to track changes in, prone to manual errors, and harder to reproduce exactly.\\n\\n- Collaboration and governance\\n  - Databases provide centralized data, access controls, and audit trails.\\n  - Excel files can get out of sync when shared.\\n\\n- Ecosystem and integration\\n  - SQL connects directly to data warehouses and BI tools; Python can orchestrate workflows, pull data from APIs, and build models.\\n  - Excel is great for quick ad-hoc checks, but not as a backbone for big data workflows.\\n\\nWhen Excel still makes sense: for small datasets, quick ad-hoc analysis, or a simple scratchpad.\\n\\nTip: For big datasets, start with SQL to fetch and summarize data, then use Python for deeper analysis or modeling.'},\n",
              " {'role': 'user', 'content': 'Please highlight the most important point'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Key point: Excel isnâ€™t built for big data. For large datasets, use SQL (for scalable querying/aggregation) and Python (for deeper analysis), because they handle volume, speed, and reproducibility much better.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat('hi')"
      ],
      "metadata": {
        "id": "wcxyVhOEo9FP",
        "outputId": "d9be943f-f93c-43ec-c905-8591bd96c9bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi there! What would you like to do today? Want a quick SQL or Python example, or tips for setting up a big-data workflow? Tell me your dataset size and goal, and Iâ€™ll tailor a tiny demo.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat('comparing python sql excel r')"
      ],
      "metadata": {
        "id": "SAzUWOI8pDds",
        "outputId": "c55a6205-7fb8-4e8d-eba4-5bda7523b731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nice quick comparison, friend. Hereâ€™s a simple compass for Python, SQL, Excel, and R.\\n\\n- Excel\\n  - Best for: small datasets, quick checks, ad-hoc analysis, dashboards.\\n  - Pros: easy UI, fast for tiny tasks, widely familiar.\\n  - Cons: memory/row limits, not scalable, hard to reproduce/collaborate.\\n\\n- SQL\\n  - Best for: querying and shaping data stored in databases/data warehouses.\\n  - Pros: handles large volumes, fast, reliable, good for reproducible pipelines and governance.\\n  - Cons: not ideal for advanced statistics or complex modeling out of the box.\\n\\n- Python\\n  - Best for: end-to-end analysis, data cleaning, modeling, automation, production pipelines.\\n  - Pros: huge library ecosystem (pandas, scikit-learn, etc.), versatile, easy to connect to many data sources.\\n  - Cons: learning curve, performance depends on approach and hardware.\\n\\n- R\\n  - Best for: statistics, specialized analytics, and rich visuals.\\n  - Pros: powerful stats packages, tidyverse/dplyr, excellent for reproducible reports (R Markdown).\\n  - Cons: less focused on general software engineering; memory considerations; ecosystem smaller for production pipelines.\\n\\nQuick guidance\\n- For big data: query in SQL (or a data warehouse) to summarize, then pull a manageable slice into Python or R for deeper analysis.\\n- For stats-heavy work: R is fantastic; for mixed workflows and production apps, Python is often the go-to.\\n- For small, quick checks: Excel works fine.\\n\\nIf you share your dataset size and goal, I can suggest a tiny, practical setup.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatbot\n",
        "Using `Gradio` to build a chatbot that we control its workflow."
      ],
      "metadata": {
        "id": "YhN0hJx-wjzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = \"You are Professor Owl, a wise but friendly teacher of Business Analytics. Explain concepts clearly and simply, using gentle guidance.\"\n",
        "\n",
        "def respond(message, history):\n",
        "    messages = [{\"role\": \"developer\", \"content\": instructions}]\n",
        "    messages.extend({\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in history)\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "\n",
        "    response = client.responses.create(\n",
        "        model=MODEL,\n",
        "        input=messages,\n",
        "        text={\"verbosity\": \"low\"}\n",
        "    )\n",
        "    return response.output_text\n",
        "\n",
        "demo = gr.ChatInterface(\n",
        "    respond,\n",
        "    type=\"messages\",\n",
        "    title=\"ðŸ¦‰ Professor Owl â€“ Business Analytics Helper\",\n",
        "    description=\"Ask Professor Owl anything data analytics!\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)  # Add debug=True to debug, if needed"
      ],
      "metadata": {
        "id": "lQtzyh2Exyo1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "1c50082a-3083-427a-a307-436aff3486e5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ea757ea1ef3651199b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ea757ea1ef3651199b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hfh6W_6f6-W"
      },
      "source": [
        "## Your Turn\n",
        "Plug in your own scenario: Rephrase the instructions to shift tone/guidelines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcHECt7Uf6-W"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}